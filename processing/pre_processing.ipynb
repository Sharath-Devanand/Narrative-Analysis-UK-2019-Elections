{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json(\"processed.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    link_pattern = r\"\\b(?:https?://)\\S+\\b\"\n",
    "    return re.sub(link_pattern, \"\", text)\n",
    "\n",
    "\n",
    "data_df[\"text\"] = data_df[\"text\"].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "data_df[\"unicoded\"] = data_df[\"text\"].astype(\"unicode\").astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_punctuation(tweet_column):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    cleaned_tweets = []\n",
    "\n",
    "    for tweet in tweet_column:\n",
    "        # Remove punctuation\n",
    "        tweet = tweet.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        # Remove stop words\n",
    "        words = tweet.split()\n",
    "        filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "        cleaned_tweets.append(\" \".join(filtered_words))\n",
    "\n",
    "    return cleaned_tweets\n",
    "\n",
    "\n",
    "def amend_mentions(tweet_column):\n",
    "    # Use regular expression to remove mentions\n",
    "    pattern = re.compile(r\"@[a-zA-Z0-9_]+\")\n",
    "    cleaned_tweets = [re.sub(pattern, \"@@mention\", tweet) for tweet in tweet_column]\n",
    "    return cleaned_tweets\n",
    "\n",
    "\n",
    "# Remove emojis\n",
    "def remove_emojis(tweet_column):\n",
    "    # Use regular expression to remove emojis\n",
    "    pattern = re.compile(r\"(:\\w+:)\")\n",
    "    cleaned_tweets = [re.sub(pattern, \"\", tweet) for tweet in tweet_column]\n",
    "    return cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"preprocessed\"] = data_df[\"unicoded\"].apply(remove_stopwords_and_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"preprocessed\"] = data_df[\"preprocessed\"].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"preprocessed\"] = data_df[\"preprocessed\"].apply(amend_mentions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com6018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
